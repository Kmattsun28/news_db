import requests
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from app.script.db import SessionLocal
from app.script.models import NewsArticle
from app.script.debug import debug_printer as d
from app.script.summarizer import summarize_text
from app.script.utils_scraper import detect_currency_tags

class FinnhubNewsCollector:
    """
    Finnhub API ã‚’ä½¿ç”¨ã—ã¦ç‚ºæ›¿å¸‚å ´ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key: Finnhub APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•° FINNHUB_API_KEY ã‹ã‚‰ã‚‚å–å¾—å¯èƒ½ï¼‰
        """
        self.api_key = api_key or os.getenv("FINNHUB_API_KEY")
        if not self.api_key:
            raise ValueError("Finnhub APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚FINNHUB_API_KEYç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã™ã‚‹ã‹ã€api_keyãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        
        self.base_url = "https://finnhub.io/api/v1"
        self.session = requests.Session()
        
        # ç‚ºæ›¿é–¢é€£ã®ã‚«ãƒ†ã‚´ãƒªè¨­å®š
        self.forex_categories = ["forex", "general"]
        
        d.print(f"Finnhub News Collector initialized with API key: {self.api_key[:8]}...", level="info")
    
    def get_market_news(self, category: str = "forex", limit: int = 50, minutes_back: int = 30) -> List[Dict]:
        """
        Finnhub APIã‹ã‚‰å¸‚å ´ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆæ™‚é–“ç¯„å›²æŒ‡å®šå¯¾å¿œï¼‰
        
        Args:
            category: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚«ãƒ†ã‚´ãƒª ("forex", "general" ãªã©)
            limit: å–å¾—ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°ã®ä¸Šé™
            minutes_back: ä½•åˆ†å‰ã¾ã§ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹ã‹
            
        Returns:
            ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ãƒªã‚¹ãƒˆ
        """
        from datetime import datetime, timedelta
        import time
        
        # ç¾åœ¨æ™‚åˆ»ã¨æŒ‡å®šåˆ†å‰ã®æ™‚åˆ»ã‚’Unixã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§è¨ˆç®—
        now = datetime.now()
        past_time = now - timedelta(minutes=minutes_back)
        
        from_timestamp = int(past_time.timestamp())
        to_timestamp = int(now.timestamp())
        
        url = f"{self.base_url}/news"
        params = {
            "category": category,
            "token": self.api_key,
            "from": from_timestamp,
            "to": to_timestamp
        }
        
        try:
            d.print(f"Fetching {category} news from Finnhub API (last {minutes_back} minutes)...", level="debug")
            d.print(f"Time range: {past_time.strftime('%Y-%m-%d %H:%M:%S')} to {now.strftime('%Y-%m-%d %H:%M:%S')}", level="debug")
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            news_data = response.json()
            
            if not isinstance(news_data, list):
                d.print(f"Unexpected response format from Finnhub API: {type(news_data)}", level="error")
                return []
            
            # æ™‚é–“ç¯„å›²å†…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆAPIã®ä»•æ§˜ã«ã‚ˆã‚Šå¿µã®ãŸã‚ï¼‰
            filtered_news = []
            for article in news_data:
                article_time = article.get("datetime", 0)
                if from_timestamp <= article_time <= to_timestamp:
                    filtered_news.append(article)
            
            # limitã§åˆ¶é™
            limited_news = filtered_news[:limit] if len(filtered_news) > limit else filtered_news
            
            d.print(f"Retrieved {len(limited_news)} {category} news articles (from {len(news_data)} total)", level="info")
            return limited_news
            
        except requests.exceptions.RequestException as e:
            d.print(f"Finnhub API request failed: {e}", level="error")
            return []
        except Exception as e:
            d.print(f"Unexpected error fetching Finnhub news: {e}", level="error")
            return []
    
    currency_keywords = [
        # USDé–¢é€£
        "USD", "US Dollar", "Dollar", "ç±³ãƒ‰ãƒ«", "ãƒ‰ãƒ«", "Greenback",
        # EURé–¢é€£
        "EUR", "Euro", "ãƒ¦ãƒ¼ãƒ­", "æ¬§å·é€šè²¨",
        # JPYé–¢é€£
        "JPY", "Japanese Yen", "Yen", "æ—¥æœ¬å††", "å††",
        # ä¸­å¤®éŠ€è¡Œãƒ»æ”¿ç­–
        "Bank of Japan", "BOJ", "æ—¥éŠ€", "æ—¥æœ¬éŠ€è¡Œ",
        "Federal Reserve", "FRB", "Fed", "ç±³é€£é‚¦æº–å‚™åˆ¶åº¦ç†äº‹ä¼š",
        "European Central Bank", "ECB", "æ¬§å·ä¸­å¤®éŠ€è¡Œ",
        # ãã®ä»–
        "FX", "Foreign Exchange", "ç‚ºæ›¿", "ç‚ºæ›¿ç›¸å ´", "FOMC", "é‡‘èæ”¿ç­–"
    ]

    usd_sources = [
        "CNBC", "Bloomberg", "Reuters", "Wall Street Journal", "MarketWatch", "Forexlive", "Yahoo Finance", "Business Insider", "Forbes", "NY Times", "AP", "Fox Business", "CNN", "Barron's", "Motley Fool", "Seeking Alpha", "US Treasury", "Federal Reserve", "WSJ", "USA Today", "TheStreet", "Investopedia", "Kiplinger", "Morningstar", "S&P Global", "Nasdaq", "Zacks", "The Economist", "Politico", "Fortune", "US News", "ABC News", "CBS News", "NBC News", "NPR"
    ]
    eur_sources = [
        "Financial Times", "Handelsblatt", "Le Monde", "Reuters", "Bloomberg", "ECB", "The Guardian", "BBC", "DW", "El PaÃ­s", "Il Sole 24 Ore", "Les Echos", "Frankfurter Allgemeine", "Euronews", "Swissinfo", "RTE",
        "SÃ¼ddeutsche Zeitung", "La Stampa", "La Repubblica", "Die Welt", "Le Figaro", "Der Spiegel", "Politico Europe", "De Tijd", "NRC Handelsblad", "Het Financieele Dagblad", "BÃ¸rsen", "Dagens Nyheter", "Svenska Dagbladet", "Aftenposten", "Helsingin Sanomat", "PÃºblico", "Expresso", "Kathimerini", "Cyprus Mail", "Irish Times", "Irish Independent", "The Times", "The Telegraph", "Sky News", "L'Express", "Ouest-France", "Trouw", "Volkskrant", "VRT NWS", "NOS", "RTL Nieuws", "Le Soir", "La Libre Belgique"
    ]
    jpy_sources = [
        "Nikkei", "NHK", "æ—¥çµŒ", "æœæ—¥æ–°è", "èª­å£²æ–°è", "æ—¥æœ¬çµŒæ¸ˆæ–°è", "BOJ", "æ¯æ—¥æ–°è", "å…±åŒé€šä¿¡", "Bloomberg Japan", "Reuters Japan", "æ±æ´‹çµŒæ¸ˆ", "ç”£çµŒæ–°è", "æ™‚äº‹é€šä¿¡", "Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    ]
    usd_countries = ["United States", "US", "America", "ç±³å›½", "USA"]
    eur_countries = ["Europe", "EU", "Eurozone", "Germany", "France", "æ¬§å·", "ãƒ¦ãƒ¼ãƒ­åœ", "ãƒ‰ã‚¤ãƒ„", "ãƒ•ãƒ©ãƒ³ã‚¹"]
    jpy_countries = ["Japan", "æ—¥æœ¬", "Tokyo", "æ±äº¬"]

    pair_keywords = {
        "EUR/USD": ["EUR/USD", "ãƒ¦ãƒ¼ãƒ­ãƒ‰ãƒ«", "Euro Dollar"],
        "USD/JPY": ["USD/JPY", "ãƒ‰ãƒ«å††", "Dollar Yen"],
        "EUR/JPY": ["EUR/JPY", "ãƒ¦ãƒ¼ãƒ­å††", "Euro Yen"]
    }

    @staticmethod
    def is_currency_related(article: Dict) -> bool:
        source = article.get("source", "")
        headline = article.get("headline", "")
        summary = article.get("summary", "")
        url = article.get("url", "")
        text = (headline + " " + summary + " " + url).lower()
        # ã‚½ãƒ¼ã‚¹åˆ¤å®š
        for s in FinnhubNewsCollector.usd_sources + FinnhubNewsCollector.eur_sources + FinnhubNewsCollector.jpy_sources:
            if s.lower() in source.lower():
                return True
        # å›½ååˆ¤å®š
        for c in FinnhubNewsCollector.usd_countries + FinnhubNewsCollector.eur_countries + FinnhubNewsCollector.jpy_countries:
            if c.lower() in text:
                return True
        # å†…å®¹åˆ¤å®šï¼ˆheadline, summary, urlã«é€šè²¨é–¢é€£ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹å ´åˆï¼‰
        for k in FinnhubNewsCollector.currency_keywords:
            if k.lower() in text:
                return True
        return False

    @staticmethod
    def classify_currency_pair(article: Dict) -> str:
        text = (article.get("headline", "") + " " + article.get("summary", "") + " " + article.get("url", "")).lower()
        for pair, keywords in FinnhubNewsCollector.pair_keywords.items():
            for kw in keywords:
                if kw.lower() in text:
                    return pair
        return "OTHER"
    
    @staticmethod
    def classify_currency_pair_from_text(headline: str, summary: str, url: str) -> str:
        """
        headline, summary, urlã‹ã‚‰é€šè²¨ãƒšã‚¢ã‚’åˆ¤å®š
        """
        text = (headline or "") + " " + (summary or "") + " " + (url or "")
        text = text.lower()
        pair_keywords = {
            "EUR/USD": ["eur/usd", "ãƒ¦ãƒ¼ãƒ­ãƒ‰ãƒ«", "euro dollar"],
            "USD/JPY": ["usd/jpy", "ãƒ‰ãƒ«å††", "dollar yen"],
            "EUR/JPY": ["eur/jpy", "ãƒ¦ãƒ¼ãƒ­å††", "euro yen"]
        }
        for pair, keywords in pair_keywords.items():
            for kw in keywords:
                if kw in text:
                    return pair
        return "OTHER"

    def get_forex_news(self, limit: int = 50, minutes_back: int = 30) -> List[Dict]:
        """
        ç‚ºæ›¿é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆæ™‚é–“ç¯„å›²æŒ‡å®šå¯¾å¿œï¼‰
        
        Args:
            limit: å–å¾—ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°ã®ä¸Šé™
            minutes_back: ä½•åˆ†å‰ã¾ã§ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹ã‹
            
        Returns:
            ç‚ºæ›¿ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ãƒªã‚¹ãƒˆ
        """
        all_news = []
        
        for category in self.forex_categories:
            news = self.get_market_news(category, limit // len(self.forex_categories), minutes_back)
            all_news.extend(news)
        
        # é‡è¤‡é™¤å»ï¼ˆURLãƒ™ãƒ¼ã‚¹ï¼‰
        seen_urls = set()
        unique_news = []
        for article in all_news:
            if article.get("url") and article["url"] not in seen_urls:
                seen_urls.add(article["url"])
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šã‚’å…ƒã«æˆ»ã™
                if self.is_currency_related(article):
                    unique_news.append(article)
        
        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        unique_news.sort(key=lambda x: x.get("datetime", 0), reverse=True)
        
        return unique_news[:limit]
    
    def convert_to_news_article(self, finnhub_article: Dict) -> Optional[NewsArticle]:
        """
        Finnhub APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’NewsArticleãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        
        Args:
            finnhub_article: Finnhub APIã‹ã‚‰å–å¾—ã—ãŸè¨˜äº‹ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            NewsArticleã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ã¾ãŸã¯å¤‰æ›å¤±æ•—æ™‚ã¯None
        """
        try:
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
            if not finnhub_article.get("headline") or not finnhub_article.get("url"):
                d.print(f"Missing required fields in article: {finnhub_article}", level="warning")
                return None
            
            # datetimeã®å¤‰æ›ï¼ˆUnix timestampã‹ã‚‰ï¼‰
            datetime_unix = finnhub_article.get("datetime", 0)
            if datetime_unix:
                published = datetime.fromtimestamp(datetime_unix)
            else:
                published = datetime.now()
            
            # è¦ç´„ã®ç”Ÿæˆ
            summary_text = finnhub_article.get("summary", "")
            if summary_text and len(summary_text) > 100:
                # é•·ã„å ´åˆã¯è¦ç´„ã‚’ç”Ÿæˆ
                summary = summarize_text(summary_text)
            else:
                # çŸ­ã„å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨ã€ãªã‘ã‚Œã°headlineã‚’ä½¿ç”¨
                summary = summary_text or finnhub_article.get("headline", "")
            
            currency_pair = self.classify_currency_pair(finnhub_article)
            full_text = finnhub_article.get("summary", "") + " " + finnhub_article.get("headline", "")
            currency_tags = detect_currency_tags(full_text)

            return NewsArticle(
                category="finnhub_forex",
                title=finnhub_article["headline"],
                summary=summary,
                url=finnhub_article["url"],
                published=published,
                currency_tags=currency_tags
            )
            
        except Exception as e:
            d.print(f"Error converting Finnhub article to NewsArticle: {e}", level="error")
            return None
    
    def fetch_and_store_finnhub_news(self, limit: int = 30, minutes_back: int = 30) -> int:
        """
        Finnhub APIã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆæ™‚é–“ç¯„å›²æŒ‡å®šå¯¾å¿œãƒ»ãƒãƒƒãƒå‡¦ç†ç‰ˆï¼‰
        
        Args:
            limit: å–å¾—ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°ã®ä¸Šé™
            minutes_back: ä½•åˆ†å‰ã¾ã§ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹ã‹
            
        Returns:
            æ–°è¦ä¿å­˜ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æ•°
        """
        session = SessionLocal()
        new_articles_count = 0
        batch_size = 5  # Finnhubã¯å‡¦ç†ãŒé‡ã„ã®ã§å°ã•ã‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
        current_batch = 0
        
        try:
            d.print(f"Starting Finnhub news collection (limit: {limit}, last {minutes_back} minutes)", level="info")
            
            # Finnhubã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆæ™‚é–“ç¯„å›²æŒ‡å®šï¼‰
            finnhub_news = self.get_forex_news(limit, minutes_back)
            
            if not finnhub_news:
                d.print(f"No news retrieved from Finnhub API for the last {minutes_back} minutes", level="warning")
                return 0
            
            d.print(f"Processing {len(finnhub_news)} articles from Finnhub (last {minutes_back} minutes)", level="info")
            
            for article_data in finnhub_news:
                try:
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šã‚’å…ƒã«æˆ»ã™
                    if not self.is_currency_related(article_data):
                        continue
                    existing = session.query(NewsArticle).filter_by(
                        url=article_data.get("url")
                    ).first()
                    if existing:
                        d.print(f"â© Article already exists: {article_data.get('headline', 'No title')[:50]}...", level="debug")
                        continue
                    news_article = self.convert_to_news_article(article_data)
                    if news_article:
                        session.add(news_article)
                        new_articles_count += 1
                        current_batch += 1
                        d.print(f"âœ… New Finnhub article: {news_article.title[:50]}...", level="info")
                        
                        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰ä¸­é–“ã‚³ãƒŸãƒƒãƒˆ
                        if current_batch >= batch_size:
                            try:
                                session.commit()
                                d.print(f"ğŸ“¦ Finnhub batch commit: {current_batch} articles saved", level="info")
                                current_batch = 0
                            except Exception as commit_error:
                                d.print(f"âŒ Finnhub batch commit failed: {commit_error}", level="error")
                                session.rollback()
                                current_batch = 0
                    else:
                        d.print(f"âŒ Failed to convert article: {article_data.get('headline', 'No title')[:50]}...", level="warning")
                        
                except Exception as article_error:
                    d.print(f"Error processing Finnhub article: {article_error}", level="error")
                    continue
            
            # æ®‹ã‚Šã®è¨˜äº‹ã‚’ã‚³ãƒŸãƒƒãƒˆ
            if current_batch > 0:
                try:
                    session.commit()
                    d.print(f"ğŸ“¦ Finnhub final batch commit: {current_batch} articles saved", level="info")
                except Exception as commit_error:
                    d.print(f"âŒ Finnhub final batch commit failed: {commit_error}", level="error")
                    session.rollback()

            d.print(f"ğŸ†— Finnhub news collection completed. New articles: {new_articles_count}", level="info")
            
            return new_articles_count
            
        except Exception as e:
            session.rollback()
            d.print(f"Error in fetch_and_store_finnhub_news: {e}", level="error")
            return 0
        finally:
            session.close()


def fetch_finnhub_forex_news(limit: int = 30, minutes_back: int = 30) -> int:
    """
    Finnhub APIã‹ã‚‰ç‚ºæ›¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã¦DBã«ä¿å­˜ã™ã‚‹é–¢æ•°ï¼ˆæ™‚é–“ç¯„å›²æŒ‡å®šå¯¾å¿œï¼‰
    ï¼ˆæ—¢å­˜ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±åˆã—ã‚„ã™ã„ã‚ˆã†ç‹¬ç«‹ã—ãŸé–¢æ•°ã¨ã—ã¦æä¾›ï¼‰
    
    Args:
        limit: å–å¾—ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°ã®ä¸Šé™
        minutes_back: ä½•åˆ†å‰ã¾ã§ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹ã‹
        
    Returns:
        æ–°è¦ä¿å­˜ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æ•°
    """
    try:
        collector = FinnhubNewsCollector()
        return collector.fetch_and_store_finnhub_news(limit, minutes_back)
    except Exception as e:
        d.print(f"Error in fetch_finnhub_forex_news: {e}", level="error")
        return 0


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆéå»30åˆ†é–“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
    d.print("Testing Finnhub News Collector (last 30 minutes)...", level="info")
    result = fetch_finnhub_forex_news(limit=10, minutes_back=30)
    d.print(f"Test completed. New articles: {result}", level="info")
